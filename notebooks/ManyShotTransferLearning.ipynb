{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from MLD import multi_lens_distortion\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true' \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Select GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "def network_1():\n",
    "    # Load pre-trained DenseNet201 and ResNet101V2 models\n",
    "    dense_net_full = tf.keras.applications.DenseNet201(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "    res_net_full = tf.keras.applications.ResNet101V2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Create a new model with only the first 54 layers of DenseNet201\n",
    "    dense_net = tf.keras.Model(inputs=dense_net_full.input, outputs=dense_net_full.layers[178].output)\n",
    "\n",
    "    # Create a new model with only the first 54 layers of ResNet101V2\n",
    "    res_net = tf.keras.Model(inputs=res_net_full.input, outputs=res_net_full.layers[178].output)\n",
    "\n",
    "    # Define input layer\n",
    "    input = layers.Input(shape=IMG_SHAPE)\n",
    "\n",
    "    # Extract features using the modified models\n",
    "    den_features = dense_net(input)\n",
    "    res_features = res_net(input)\n",
    "\n",
    "    # Global Average Pooling (GAP)\n",
    "    den_features = layers.GlobalAveragePooling2D()(den_features)\n",
    "    res_features = layers.GlobalAveragePooling2D()(res_features)\n",
    "\n",
    "    # Concatenate extracted features\n",
    "    concatenated = layers.Concatenate()([den_features, res_features])\n",
    "\n",
    "    # Dense layers for classification\n",
    "    z = layers.Dropout(0.4)(concatenated)\n",
    "    z = layers.Dense(512, activation='relu')(z)\n",
    "    # z = layers.Dropout(0.2)(z)\n",
    "    z = layers.Dense(2, activation='softmax')(z)\n",
    "\n",
    "    # Final model\n",
    "    model = Model(inputs=input, outputs=z)\n",
    "    model.compile(optimizer=optimizers.Adam(1e-4), loss=\"CategoricalCrossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = network_1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "filenames = next(walk('./NLCB/Data3/'), (None, None, []))[2]  # [] if no file\n",
    "filenames_val = next(walk('./NLCB/Data3/Validation/'), (None, None, []))[2]  # [] if no file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_generator(directory):\n",
    "    for filepath in glob.glob(os.path.join(directory, '*.png')):  # assuming jpeg images\n",
    "        image = tf.io.read_file(filepath)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        label = []\n",
    "        label[0] = 1 if filepath[4] == 'n' else 0  # Check the 5th character from the end for 'n'\n",
    "        label[1] = 0 if filepath[4] != 'n' else 1\n",
    "        yield image, label\n",
    "\n",
    "\n",
    "\n",
    "def custom_preprocessing_function(img):\n",
    "\n",
    "    if tf.random.uniform((), minval= 0, maxval=1) > 0.5:\n",
    "        nbr_rot = tf.random.uniform(shape=[], minval=1, maxval=4, dtype=tf.int32)\n",
    "        img =tf.image.rot90(img, k=nbr_rot)\n",
    "\n",
    "    img = tf.image.random_hue(img, 0.08)\n",
    "    img = tf.image.random_contrast(img, 0.7, 1.3)\n",
    "    img = tf.image.random_brightness(img, 0.2)\n",
    "    img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    # print(img.shape)\n",
    "    # img = tf.image.random_crop(img, (int(img.shape[0]/2),int(img.shape[1]/2), 3))\n",
    "    img = tf.image.random_crop(img, (224, 224, 3))\n",
    "    img = img/255.\n",
    "    img = tf.image.resize(img,(224,224))\n",
    "    img = tf.numpy_function(\n",
    "        multi_lens_distortion, \n",
    "        [img, 4, (80, 110), (-0.4, 0.4)],   \n",
    "        tf.uint8\n",
    "    )\n",
    "\n",
    "    return img\n",
    "\n",
    "def validation_preprocessing_function(img):\n",
    "    # img = tf.image.random_crop(img, (224, 224, 3))\n",
    "    img = img/255.\n",
    "    img = tf.image.resize(img,(224,224))\n",
    "\n",
    "# Paths\n",
    "train_data_dir = \"./NLCB/Data3/Training/\"\n",
    "validation_data_dir = \"./NLCB/Data3/Validation/\"\n",
    "\n",
    "# Create a data generator for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=custom_preprocessing_function  # Add more augmentations here\n",
    ")\n",
    "\n",
    "# Create a data generator for validation data\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=validation_preprocessing_function)\n",
    "\n",
    "# Use custom data generator for training and validation datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adamax(1e-4), loss=\"CategoricalCrossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# # considering you want to monitor accuracy:\n",
    "# acc_thresh = 0.95\n",
    "\n",
    "# class MyCallback(Callback):\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         logs = logs or {}\n",
    "#         val_accuracy = logs.get('val_accuracy')\n",
    "#         if val_accuracy is not None and val_accuracy > acc_thresh:\n",
    "#             print(f'\\nEpoch {epoch}: Early stopping as val_accuracy is {val_accuracy}')\n",
    "#             self.model.stop_training = True\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=len(train_generator),\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=len(validation_generator),\n",
    "#     epochs=200,\n",
    "#     callbacks=[MyCallback()]\n",
    "# )\n",
    "\n",
    "# model.save('./PWCModel/')\n",
    "\n",
    "\n",
    "# Parameters for EarlyStopping and ModelCheckpoint\n",
    "patience = 40\n",
    "\n",
    "# Setting up callbacks for early stopping on minimum validation loss and saving the best model\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=patience,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity.\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    './PWCModel/best_model.h5',  # Path where the model will be saved\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,  # Only the best model according to the validation loss is saved\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping_callback, model_checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Save the overall model after training (optional, as the best model is already saved)\n",
    "model.save('./PWCModel/best_PWC_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, opset=13)\n",
    "onnx.save(onnx_model, \"./PWCModel.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
